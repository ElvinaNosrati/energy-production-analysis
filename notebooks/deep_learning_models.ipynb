{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c9b265b-301c-4657-9ca5-f3786402579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "stl_path = \"../processed_data/stl_energy_production_with_engineered_features.csv\"\n",
    "hp_path = \"../processed_data/hp_energy_production_with_engineered_features.csv\"\n",
    "\n",
    "stl_df = pd.read_csv(stl_path)\n",
    "hp_df = pd.read_csv(hp_path)\n",
    "\n",
    "feature_cols = [\n",
    "    \"Water_Flow_m3_s\", \"avgtempC\", \"totalprecipMM\", \"humidity\", \"pressureMB\",\n",
    "    \"WaterFlow_Diff_1d\", \"WaterFlow_Diff_7d\", \"WaterFlow_3day_avg\", \"WaterFlow_7day_avg\",\n",
    "    \"Temp_Deviation\", \"WaterFlow_Humidity\", \"month_sin\", \"month_cos\",\n",
    "    \"Normalized_Efficiency\", \"Prev_Day_Efficiency\", \"Prev_Week_Efficiency\"\n",
    "]\n",
    "target_col = \"Efficiency\"\n",
    "\n",
    "def prepare_data(df):\n",
    "    X = df[feature_cols].values\n",
    "    y = df[target_col].values.reshape(-1, 1)\n",
    "\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "    X = scaler_X.fit_transform(X)\n",
    "    y = scaler_y.fit_transform(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return (\n",
    "        torch.tensor(X_train, dtype=torch.float32), torch.tensor(X_test, dtype=torch.float32),\n",
    "        torch.tensor(y_train, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32),\n",
    "        scaler_y\n",
    "    )\n",
    "\n",
    "stl_X_train, stl_X_test, stl_y_train, stl_y_test, stl_scaler_y = prepare_data(stl_df)\n",
    "hp_X_train, hp_X_test, hp_y_train, hp_y_test, hp_scaler_y = prepare_data(hp_df)\n",
    "\n",
    "batch_size = 64\n",
    "stl_train_loader = DataLoader(TensorDataset(stl_X_train, stl_y_train), batch_size=batch_size, shuffle=True)\n",
    "stl_test_loader = DataLoader(TensorDataset(stl_X_test, stl_y_test), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "hp_train_loader = DataLoader(TensorDataset(hp_X_train, hp_y_train), batch_size=batch_size, shuffle=True)\n",
    "hp_test_loader = DataLoader(TensorDataset(hp_X_test, hp_y_test), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4556d5ba-3760-4700-8407-b85337e5bb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HydropowerEfficiencyNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(HydropowerEfficiencyNN, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),  \n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.SiLU(),  \n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(32, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(16, 1)  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 3:\n",
    "            x = x[:, -1, :]\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "input_dim = len(feature_cols)\n",
    "device = torch.device(\"cpu\")  \n",
    "model = HydropowerEfficiencyNN(input_dim=len(feature_cols)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d170cd4-5f41-4b33-97ae-55f22cd0d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9b64471-f9ad-412d-a08d-1915757d7e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elvinanosrati/Capstone/energy-production-analysis/myenv-py311/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Train Loss: 0.0197, Test Loss: 3.9736\n",
      "Epoch 10/50, Train Loss: 0.0129, Test Loss: 2.0523\n",
      "Epoch 15/50, Train Loss: 0.0107, Test Loss: 0.4035\n",
      "Epoch 20/50, Train Loss: 0.0084, Test Loss: 0.0416\n",
      "Early stopping triggered at epoch 24\n",
      "Epoch 5/50, Train Loss: 0.0152, Test Loss: 0.2302\n",
      "Epoch 10/50, Train Loss: 0.0127, Test Loss: 0.1595\n",
      "Epoch 15/50, Train Loss: 0.0106, Test Loss: 0.5742\n",
      "Early stopping triggered at epoch 20\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, test_loader, num_epochs=50, patience=7):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-4)  # Increased weight decay\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)  \n",
    "\n",
    "    train_losses, test_losses = [], []\n",
    "    best_test_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        train_losses.append(epoch_loss / max(1, len(train_loader)))\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                y_pred = model(X_batch)\n",
    "                test_loss += criterion(y_pred, y_batch).item()\n",
    "        \n",
    "        test_loss /= max(1, len(test_loader))\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        scheduler.step(test_loss)\n",
    "\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            patience_counter = 0 \n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}\")\n",
    "\n",
    "    return train_losses, test_losses\n",
    "train_losses_stl, test_losses_stl = train_model(model, stl_train_loader, stl_test_loader, num_epochs=50)\n",
    "train_losses_hp, test_losses_hp = train_model(model, hp_train_loader, hp_test_loader, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd46d097-1641-44d8-8c5c-0c1c060f6ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results - R²: 0.9490, MAE: 0.0813, RMSE: 1.3891\n",
      "\n",
      "Evaluation Results - R²: 0.9517, MAE: 0.0816, RMSE: 1.1157\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader, scaler_y):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.cpu().numpy()  \n",
    "            \n",
    "            y_pred_batch = model(X_batch).cpu().numpy()\n",
    "            y_true.append(y_batch)\n",
    "            y_pred.append(y_pred_batch)\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    y_true = scaler_y.inverse_transform(y_true.reshape(-1, 1))\n",
    "    y_pred = scaler_y.inverse_transform(y_pred.reshape(-1, 1))\n",
    "\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    print(f\"\\nEvaluation Results - R²: {r2:.4f}, MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "y_true, y_pred = evaluate_model(model, stl_test_loader, stl_scaler_y)\n",
    "y_true_hp, y_pred_hp = evaluate_model(model, hp_test_loader, hp_scaler_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9d7915-c2d8-4785-a089-cc34c9c9a5fb",
   "metadata": {},
   "source": [
    "# RNN/LSTM/GRU\n",
    "Best results after several tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af43bd13-f999-4988-b0f5-ef46cf102864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences for RNN models\n",
    "def create_sequences(df, feature_cols, target_col, seq_length=14):\n",
    "    X, y = [], []\n",
    "    for i in range(len(df) - seq_length):\n",
    "        X.append(df[feature_cols].iloc[i:i+seq_length].values)  \n",
    "        y.append(df[target_col].iloc[i+seq_length])  \n",
    "    \n",
    "    return np.array(X), np.array(y).reshape(-1, 1)\n",
    "\n",
    "stl_X, stl_y = create_sequences(stl_df, feature_cols, target_col, seq_length=14)\n",
    "X_train, X_test, y_train, y_test = train_test_split(stl_X, stl_y, test_size=0.2, random_state=42)\n",
    "hp_X_train, hp_X_test, hp_y_train, hp_y_test, hp_scaler_y = prepare_data(hp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7440aee-1764-4b21-9fb3-f711a6de08d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = map(\n",
    "    lambda x: torch.tensor(x, dtype=torch.float32).to(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    (X_train, X_test, y_train, y_test)\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72ba058f-a25b-476e-a7ce-58762642808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=2, model_type=\"RNN\", dropout_rate=0.3):\n",
    "        super(RecurrentModel, self).__init__()\n",
    "        self.model_type = model_type\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        if model_type == \"RNN\":\n",
    "            self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        elif model_type == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        elif model_type == \"GRU\":\n",
    "            self.rnn = nn.GRU(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout_rate)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "\n",
    "        if out.dim() == 3: \n",
    "            out = out[:, -1, :]  \n",
    "        elif out.dim() == 2: \n",
    "            out = out.unsqueeze(1) \n",
    "\n",
    "        out = self.layer_norm(out)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b736577-850d-4da6-9aa4-4879dd1b1101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting training for 50 epochs...\n",
      "Epoch 5/50, Train Loss: 0.0045, Test Loss: 0.5502\n",
      " Early stopping triggered at epoch 8\n",
      " Starting training for 50 epochs...\n",
      "Epoch 5/50, Train Loss: 0.0078, Test Loss: 0.0025\n",
      " Early stopping triggered at epoch 8\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, test_loader, num_epochs=50, patience=7):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    \n",
    "    train_losses, test_losses = [], []\n",
    "    print(f\" Starting training for {num_epochs} epochs...\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            seq_length = 1  \n",
    "            X_batch = X_batch.view(X_batch.shape[0], seq_length, -1)\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)  \n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        train_losses.append(epoch_loss / len(train_loader))\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                X_batch = X_batch.view(X_batch.shape[0], seq_length, -1).to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = model(X_batch)\n",
    "                test_loss += criterion(y_pred, y_batch).item()\n",
    "        \n",
    "        test_loss /= len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "    \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if len(test_losses) > patience and test_losses[-1] > min(test_losses[-patience:]):\n",
    "            print(f\" Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    return train_losses, test_losses\n",
    "\n",
    "train_losses_stl_after, test_losses_stl_after = train_model(model, stl_train_loader, stl_test_loader, num_epochs=50)\n",
    "train_losses_hp_after, test_losses_hp_after = train_model(model, hp_train_loader, hp_test_loader, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f19547c-c2f6-4d99-9892-b1fc1f77b84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results - R²: 0.9983, MAE: 0.0533, RMSE: 0.2533\n",
      "Evaluation Results - R²: 0.9975, MAE: 0.0622, RMSE: 0.2516\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader, scaler_y):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_pred_batch = model(X_batch).cpu().numpy()\n",
    "            \n",
    "            if y_pred_batch.ndim == 3:\n",
    "                y_pred_batch = y_pred_batch.squeeze(1)\n",
    "                \n",
    "            y_true.append(y_batch.cpu().numpy())\n",
    "            y_pred.append(y_pred_batch)\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    y_true = scaler_y.inverse_transform(y_true.reshape(-1, 1))\n",
    "    y_pred = scaler_y.inverse_transform(y_pred.reshape(-1, 1))\n",
    "\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    print(f\"Evaluation Results - R²: {r2:.4f}, MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
    "    return r2, mae, rmse\n",
    "    \n",
    "r2_stl, mae_stl, rmse_stl = evaluate_model(model, stl_test_loader, stl_scaler_y)\n",
    "r2_hp, mae_hp, rmse_hp = evaluate_model(model, hp_test_loader, hp_scaler_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "98ba9d94-5ede-4366-a8e8-2c0a00c5abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_predictions(model, test_loader, scaler_y):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_pred_batch = model(X_batch).cpu().numpy()\n",
    "            \n",
    "            if y_pred_batch.ndim == 3:\n",
    "                y_pred_batch = y_pred_batch.squeeze(1)\n",
    "                \n",
    "            y_true.append(y_batch.cpu().numpy())\n",
    "            y_pred.append(y_pred_batch)\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    y_true = scaler_y.inverse_transform(y_true.reshape(-1, 1))\n",
    "    y_pred = scaler_y.inverse_transform(y_pred.reshape(-1, 1))\n",
    "\n",
    "    return y_true, y_pred \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d0adc24-a5b6-4c2a-b81c-4a7598cf54e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training RNN on STL Data...\n",
      " Starting training for 50 epochs...\n",
      "Epoch 5/50, Train Loss: 0.0044, Test Loss: 4.5093\n",
      " Early stopping triggered at epoch 8\n",
      "\n",
      " Training RNN on HP Data...\n",
      " Starting training for 50 epochs...\n",
      "Epoch 5/50, Train Loss: 0.0096, Test Loss: 4.1685\n",
      " Early stopping triggered at epoch 9\n",
      "\n",
      " Training LSTM on STL Data...\n",
      " Starting training for 50 epochs...\n",
      "Epoch 5/50, Train Loss: 0.0031, Test Loss: 4.3595\n",
      " Early stopping triggered at epoch 9\n",
      "\n",
      " Training LSTM on HP Data...\n",
      " Starting training for 50 epochs...\n",
      "Epoch 5/50, Train Loss: 0.0078, Test Loss: 4.2440\n",
      " Early stopping triggered at epoch 9\n",
      "\n",
      " Training GRU on STL Data...\n",
      " Starting training for 50 epochs...\n",
      "Epoch 5/50, Train Loss: 0.0039, Test Loss: 4.6015\n",
      " Early stopping triggered at epoch 9\n",
      "\n",
      " Training GRU on HP Data...\n",
      " Starting training for 50 epochs...\n",
      "Epoch 5/50, Train Loss: 0.0084, Test Loss: 4.1525\n",
      " Early stopping triggered at epoch 8\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 128  \n",
    "\n",
    "models_stl = {}\n",
    "models_hp = {}\n",
    "\n",
    "for model_type in [\"RNN\", \"LSTM\", \"GRU\"]:\n",
    "    print(f\"\\n Training {model_type} on STL Data...\")\n",
    "    model_stl = RecurrentModel(len(feature_cols), hidden_dim, model_type=model_type)\n",
    "    train_losses_stl_after, test_losses_stl_after = train_model(model_stl, stl_train_loader, stl_test_loader, num_epochs=50)\n",
    "    models_stl[model_type] = model_stl \n",
    "    \n",
    "    print(f\"\\n Training {model_type} on HP Data...\")\n",
    "    model_hp = RecurrentModel(len(feature_cols), hidden_dim, model_type=model_type)\n",
    "    train_losses_hp_after, test_losses_hp_after = train_model(model_hp, hp_train_loader, hp_test_loader, num_epochs=50)\n",
    "    models_hp[model_type] = model_hp \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "134ee6f0-2f4d-449d-bfdb-55c5946465a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results - R²: 0.0885, MAE: 0.1993, RMSE: 5.8724\n",
      "Evaluation Results - R²: 0.0931, MAE: 0.2195, RMSE: 5.8577\n",
      "Evaluation Results - R²: 0.0728, MAE: 0.2212, RMSE: 5.9228\n",
      "Evaluation Results - R²: 0.1141, MAE: 0.2083, RMSE: 4.7777\n",
      "Evaluation Results - R²: 0.1136, MAE: 0.2924, RMSE: 4.7789\n",
      "Evaluation Results - R²: 0.0939, MAE: 0.2356, RMSE: 4.8317\n"
     ]
    }
   ],
   "source": [
    "# STL Evaluation\n",
    "r2_stl_rnn, mae_stl_rnn, rmse_stl_rnn = evaluate_model(models_stl[\"RNN\"], stl_test_loader, stl_scaler_y)\n",
    "r2_stl_lstm, mae_stl_lstm, rmse_stl_lstm = evaluate_model(models_stl[\"LSTM\"], stl_test_loader, stl_scaler_y)\n",
    "r2_stl_gru, mae_stl_gru, rmse_stl_gru = evaluate_model(models_stl[\"GRU\"], stl_test_loader, stl_scaler_y)\n",
    "\n",
    "# HP Evaluation\n",
    "r2_hp_rnn, mae_hp_rnn, rmse_hp_rnn = evaluate_model(models_hp[\"RNN\"], hp_test_loader, hp_scaler_y)\n",
    "r2_hp_lstm, mae_hp_lstm, rmse_hp_lstm = evaluate_model(models_hp[\"LSTM\"], hp_test_loader, hp_scaler_y)\n",
    "r2_hp_gru, mae_hp_gru, rmse_hp_gru = evaluate_model(models_hp[\"GRU\"], hp_test_loader, hp_scaler_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4dec2541-20ea-4580-9cc8-3db05c997ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not os.path.exists(\"DL\"):\n",
    "    os.makedirs(\"DL\")\n",
    "\n",
    "def save_plot(fig, filename):\n",
    "    fig.savefig(f\"DL/{filename}.png\", bbox_inches=\"tight\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "08616bb4-6a78-440b-8daf-1546a62efcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_loss_curves(train_losses, test_losses, title, filename):\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Train Loss\", marker=\"o\")\n",
    "    plt.plot(range(1, len(test_losses) + 1), test_losses, label=\"Test Loss\", marker=\"s\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    save_plot(fig, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3eb6709a-d7a5-4e43-b28b-bb445716a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_loss_curves(train_losses_stl, test_losses_stl, \"STL Before RNN/LSTM/GRU\", \"train_loss_stl_before\")\n",
    "save_loss_curves(train_losses_hp, test_losses_hp, \"HP Before RNN/LSTM/GRU\", \"train_loss_hp_before\")\n",
    "\n",
    "save_loss_curves(train_losses_stl_after, test_losses_stl_after, \"STL RNN Loss\", \"train_loss_stl_rnn\")\n",
    "save_loss_curves(train_losses_stl_after, test_losses_stl_after, \"STL LSTM Loss\", \"train_loss_stl_lstm\")\n",
    "save_loss_curves(train_losses_stl_after, test_losses_stl_after, \"STL GRU Loss\", \"train_loss_stl_gru\")\n",
    "\n",
    "save_loss_curves(train_losses_hp_after, test_losses_hp_after, \"HP RNN Loss\", \"train_loss_hp_rnn\")\n",
    "save_loss_curves(train_losses_hp_after, test_losses_hp_after, \"HP LSTM Loss\", \"train_loss_hp_lstm\")\n",
    "save_loss_curves(train_losses_hp_after, test_losses_hp_after, \"HP GRU Loss\", \"train_loss_hp_gru\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "06152b7e-0038-45b0-b891-c9dbedf9bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_predictions(y_true, y_pred_rnn, y_pred_lstm, y_pred_gru, title, filename):\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_true, label=\"Actual\", linestyle=\"dashed\", color=\"black\")\n",
    "    plt.plot(y_pred_rnn, label=\"RNN Prediction\", alpha=0.7)\n",
    "    plt.plot(y_pred_lstm, label=\"LSTM Prediction\", alpha=0.7)\n",
    "    plt.plot(y_pred_gru, label=\"GRU Prediction\", alpha=0.7)\n",
    "    \n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.ylabel(\"Predicted Values\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    save_plot(fig, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "86b716cb-f2b0-43bb-9505-2ac8c8a57502",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all_predictions(y_true_stl, y_pred_rnn_stl, y_pred_lstm_stl, y_pred_gru_stl, \n",
    "                     \"STL - Model Predictions Comparison\", \"stl_model_predictions_comparison\")\n",
    "\n",
    "save_all_predictions(y_true_hp, y_pred_rnn_hp, y_pred_lstm_hp, y_pred_gru_hp, \n",
    "                     \"HP - Model Predictions Comparison\", \"hp_model_predictions_comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1746deed-608f-41ec-8341-527aec913d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions_plot(y_true, y_pred, title, filename):\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    plt.scatter(y_true, y_pred, alpha=0.6)\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], linestyle='--', color='red')\n",
    "    plt.xlabel(\"Actual Values\")\n",
    "    plt.ylabel(\"Predicted Values\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    save_plot(fig, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a81357ed-8c37-4dfc-8ceb-e2f7f2cdc9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predictions_plot(y_true_stl, y_pred_rnn_stl, \"STL RNN Predictions\", \"stl_rnn_predictions\")\n",
    "save_predictions_plot(y_true_stl, y_pred_lstm_stl, \"STL LSTM Predictions\", \"stl_lstm_predictions\")\n",
    "save_predictions_plot(y_true_stl, y_pred_gru_stl, \"STL GRU Predictions\", \"stl_gru_predictions\")\n",
    "\n",
    "save_predictions_plot(y_true_hp, y_pred_rnn_hp, \"HP RNN Predictions\", \"hp_rnn_predictions\")\n",
    "save_predictions_plot(y_true_hp, y_pred_lstm_hp, \"HP LSTM Predictions\", \"hp_lstm_predictions\")\n",
    "save_predictions_plot(y_true_hp, y_pred_gru_hp, \"HP GRU Predictions\", \"hp_gru_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fa67482a-5478-461c-91f0-18bac43483cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_performance_comparison(models, r2_stl, mae_stl, rmse_stl, r2_hp, mae_hp, rmse_hp, filename):\n",
    "    x = np.arange(len(models))  # Model positions on x-axis\n",
    "    width = 0.2  # Bar width\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # STL Metrics\n",
    "    ax.bar(x - 2*width, r2_stl, width, label=\"STL R²\", color=\"blue\")\n",
    "    ax.bar(x - width, mae_stl, width, label=\"STL MAE\", color=\"green\")\n",
    "    ax.bar(x, rmse_stl, width, label=\"STL RMSE\", color=\"purple\")\n",
    "\n",
    "    # HP Metrics\n",
    "    ax.bar(x + width, r2_hp, width, label=\"HP R²\", color=\"orange\")\n",
    "    ax.bar(x + 2*width, mae_hp, width, label=\"HP MAE\", color=\"red\")\n",
    "    ax.bar(x + 3*width, rmse_hp, width, label=\"HP RMSE\", color=\"brown\")\n",
    "\n",
    "    ax.set_xlabel(\"Model Type\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.set_title(\"Deep Learning Model Performance Comparison (STL vs HP)\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models, rotation=0)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    plt.savefig(f\"DL/{filename}.png\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "save_model_performance_comparison([\"RNN\", \"LSTM\", \"GRU\"], \n",
    "                                  [r2_stl_rnn, r2_stl_lstm, r2_stl_gru],  # STL R²\n",
    "                                  [mae_stl_rnn, mae_stl_lstm, mae_stl_gru],  # STL MAE\n",
    "                                  [rmse_stl_rnn, rmse_stl_lstm, rmse_stl_gru],  # STL RMSE\n",
    "                                  [r2_hp_rnn, r2_hp_lstm, r2_hp_gru],  # HP R²\n",
    "                                  [mae_hp_rnn, mae_hp_lstm, mae_hp_gru],  # HP MAE\n",
    "                                  [rmse_hp_rnn, rmse_hp_lstm, rmse_hp_gru],  # HP RMSE\n",
    "                                  \"dl_model_performance_comparison\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351165f1-cbc6-429f-b381-c584929b833b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (myenv-py311)",
   "language": "python",
   "name": "myenv-py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
